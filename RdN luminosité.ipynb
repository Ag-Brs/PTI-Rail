{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ba3dc1e-f12d-4cdb-b011-28a2761b0059",
   "metadata": {},
   "source": [
    "Chargement des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0eb70ba-a36b-4ca5-bd47-e66e3386b066",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input path : /home/abarras/Documents/TDSI/Projet Alstom/Paires d'images\n",
      "6 6\n",
      "/home/abarras/Documents/TDSI/Projet Alstom/Paires d'images/11.369/20230323_191223_BRS_L_UP_11.369_00.jpg\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "def load_images(path):\n",
    "    image_files = glob.glob(path)\n",
    "    images = []\n",
    "    for file in image_files:\n",
    "        img = cv2.imread(file)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        # Prétraitement si nécessaire\n",
    "        images.append(img)\n",
    "    return np.array(images)\n",
    "\n",
    "# Spécifier le chemin vers le répertoire contenant les images\n",
    "input_train_path = os.getcwd()+\"/Paires d'images\"\n",
    "print(f\"input path : {input_train_path}\")\n",
    "\n",
    "class_names = ['11.369', '16.109', '43.446']\n",
    "\n",
    "# Charger les images pour l'entraînement\n",
    "train_val_image_file_list = []\n",
    "train_val_label_list = []\n",
    "\n",
    "for i in range(len(class_names)):\n",
    "    for filename in glob.iglob( os.path.join(input_train_path,class_names[i]) + '/**/*.jpg', recursive=True):\n",
    "        # extract patient number and slice\n",
    "        train_val_image_file_list.append(filename)\n",
    "        train_val_label_list.append( i )     \n",
    "\n",
    "print(len(train_val_image_file_list), len(train_val_label_list))\n",
    "print(train_val_image_file_list[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dea9bb9-d36e-429f-9710-374763dcb88c",
   "metadata": {},
   "source": [
    "Création du modèle de réseau de neurones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16f817f5-183f-4718-8c34-ee776c5c7763",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00, 472.74it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from PIL import Image, ImageFilter\n",
    "# Reading images \n",
    "def ReadImages(images_files):\n",
    "    X = []\n",
    "    for index in tqdm(range(len(images_files))):\n",
    "        #image_read = cv2.imread(images_files[index], cv2.IMREAD_COLOR)\n",
    "        image_read = Image.open(images_files[index])\n",
    "       \n",
    "    X = np.asarray(X, dtype=np.uint8)\n",
    "    return X\n",
    "\n",
    "# Read images\n",
    "X_train_rgb = ReadImages(train_val_image_file_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b08c900-7799-407d-9905-cb4bd623ab15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_brightness(image, factor):\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
    "    hsv[:, :, 2] = np.clip(hsv[:, :, 2] * factor, 0, 255)\n",
    "    return cv2.cvtColor(hsv, cv2.COLOR_HSV2RGB)\n",
    "\n",
    "def build_brightness_model(input_shape):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Flatten(input_shape=input_shape))\n",
    "    model.add(layers.Dense(64, activation='relu'))\n",
    "    model.add(layers.Dense(1, activation='linear'))  # Linear activation for regression\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7bac71e5-ac4f-4c91-a3d8-72aec1eecd2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_images_with_brightness(images_files, brightness_model):\n",
    "    X = []\n",
    "    y_brightness = []\n",
    "\n",
    "    # Load and preprocess the first image separately\n",
    "    first_image_read = cv2.imread(images_files[0])\n",
    "    first_image_rgb = cv2.cvtColor(first_image_read, cv2.COLOR_BGR2RGB)\n",
    "    first_image_brightness = 1.0  # Initial brightness factor for the first image\n",
    "\n",
    "    # Add the first image to the data\n",
    "    X.append(first_image_rgb)\n",
    "    y_brightness.append(first_image_brightness)\n",
    "\n",
    "    # Train the brightness adjustment model using the first image\n",
    "    for index in tqdm(range(1, len(images_files))):\n",
    "        image_read = cv2.imread(images_files[index])\n",
    "        image_rgb = cv2.cvtColor(image_read, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Additional preprocessing if needed, e.g., resizing, normalization\n",
    "        # ...\n",
    "\n",
    "        # Extract features from the first image (brightness in this case)\n",
    "        first_image_features = [first_image_brightness]\n",
    "\n",
    "        # Predict brightness using the trained model\n",
    "        brightness_factor = brightness_model.predict(np.asarray([first_image_features]))[0, 0]\n",
    "\n",
    "        # Adjust brightness\n",
    "        adjusted_image = adjust_brightness(image_rgb, brightness_factor)\n",
    "\n",
    "        X.append(adjusted_image)\n",
    "        y_brightness.append(brightness_factor)\n",
    "\n",
    "    X = np.asarray(X, dtype=np.uint8)\n",
    "    y_brightness = np.asarray(y_brightness, dtype=np.float32)\n",
    "\n",
    "    return X, y_brightness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56f47237-04df-481d-8888-21d43d32f470",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_20630/1837279618.py:16: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return np.array(images)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'train_test_split' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m y_train_brightness \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Split the data into training and validation sets\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m X_train, X_val, y_train, y_val \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_test_split\u001b[49m(X_train_rgb, y_train_brightness, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Build the brightness adjustment model\u001b[39;00m\n\u001b[1;32m     11\u001b[0m input_shape \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m1\u001b[39m,)  \u001b[38;5;66;03m# Features from the first image (brightness in this case)\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_test_split' is not defined"
     ]
    }
   ],
   "source": [
    "# Load and preprocess images\n",
    "X_train_rgb = load_images(os.path.join(input_train_path, class_names[0], '*.jpg'))\n",
    "\n",
    "# Load brightness labels (you need to create y_train_brightness based on your data)\n",
    "y_train_brightness = ...\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_rgb, y_train_brightness, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build the brightness adjustment model\n",
    "input_shape = (1,)  # Features from the first image (brightness in this case)\n",
    "brightness_model = build_brightness_model(input_shape)\n",
    "\n",
    "# Train the brightness adjustment model\n",
    "brightness_model.fit(np.asarray([[1.0]]), np.asarray([1.0]), epochs=10, batch_size=1, verbose=0)\n",
    "\n",
    "# Read images and adjust brightness using the trained model\n",
    "X_train_adjusted, _ = read_images_with_brightness(train_val_image_file_list, brightness_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55475a4e-1de8-4296-9c56-95750c35799d",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_read = Image.open(train_val_image_file_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f79fcc9f-a930-4790-8071-d4b2d5d51fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2D, Input, UpSampling2D, Lambda\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "def create_brightness_adjustment_model(input_shape):\n",
    "    input_img = Input(shape=input_shape)\n",
    "    # Définition du modèle...\n",
    "    \n",
    "    # Exemple de modèle simple pour l'ajustement de luminosité (à adapter selon les besoins)\n",
    "    conv_1 = Conv2D(64, (3, 3), activation='relu', padding='same')(input_img)\n",
    "    upsample_1 = UpSampling2D((2, 2))(conv_1)\n",
    "    decoded_img = Conv2D(3, (3, 3), activation='sigmoid', padding='same')(upsample_1)\n",
    "\n",
    "    model = Model(inputs=input_img, outputs=decoded_img)\n",
    "    return model\n",
    "\n",
    "# Créer le modèle\n",
    "input_shape = train_val_image_file_list[0].shape  # Utiliser la forme de la première image pour définir l'entrée du modèle\n",
    "brightness_model = create_brightness_adjustment_model(input_shape)\n",
    "\n",
    "# Compiler le modèle\n",
    "brightness_model.compile(optimizer='adam', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64aa4761-a081-4fc8-b95f-7ab8db6c7621",
   "metadata": {},
   "source": [
    "Entrainement du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e961dde7-9f8a-4208-919a-930c37254cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entraînement du modèle\n",
    "brightness_model.fit(X_train, X_train, epochs=10, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eadcc24-e222-4442-90fc-14bc549fd18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from PIL import Image\n",
    "\n",
    "# Charger les données et les étiquettes de luminosité (les étiquettes dépendront de votre ensemble de données)\n",
    "# X_train, y_train = chargement_des_images_et_des_etiquettes()\n",
    "path_data = os.getcwd()+'/BDD étiquettes.csv'\n",
    "data = pd.read_csv(path_data)\n",
    "\n",
    "X_train_paths = data['Image']\n",
    "y_train = data['Etiquette']\n",
    "\n",
    "# Charger le chemin de la première image dans X_train_paths\n",
    "chemin_image = X_train_paths[0]\n",
    "\n",
    "# Charger l'image à partir du chemin spécifié\n",
    "image = Image.open(chemin_image)\n",
    "\n",
    "# Prétraitement des données\n",
    "# Normaliser les valeurs des pixels, redimensionner les images, etc.\n",
    "# X_train = pretraitement_des_images(X_train)\n",
    "\n",
    "# Construire le modèle CNN\n",
    "# model = models.Sequential()\n",
    "# model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(largeur_image, hauteur_image, canaux)))\n",
    "# model.add(layers.MaxPooling2D((2, 2)))\n",
    "# model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "# model.add(layers.MaxPooling2D((2, 2)))\n",
    "# model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "# model.add(layers.MaxPooling2D((2, 2)))\n",
    "# model.add(layers.Flatten())\n",
    "# model.add(layers.Dense(128, activation='relu'))\n",
    "# model.add(layers.Dense(1, activation='linear'))  # Couche de sortie pour la prédiction de luminosité\n",
    "\n",
    "# Compiler le modèle\n",
    "# model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
    "\n",
    "# Entraîner le modèle\n",
    "# model.fit(X_train, y_train, epochs=nb_epochs, batch_size=batch_size, validation_split=0.2)\n",
    "\n",
    "# Afficher la première image de la base de données\n",
    "plt.imshow(X_train_paths[0])\n",
    "plt.axis('off')  # Masquer les axes\n",
    "plt.title('Première image de la base de données')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c16691-9735-4326-b9da-1bd073cd6082",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d62970-0ddb-4928-bd8d-e4b542017d4a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
